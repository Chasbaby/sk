<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <!-- 日志存放路径 -->
	<property name="log.path" value="/home/ruoyi/logs" />

    <!-- 日志输出格式 -->
	<property name="log.pattern" value="%d{HH:mm:ss.SSS} [%thread] %-5level %logger{20} - [%method,%line] - %msg%n" />

	<!-- 控制台输出 -->
	<appender name="console" class="ch.qos.logback.core.ConsoleAppender">
		<encoder>
			<pattern>${log.pattern}</pattern>
		</encoder>
	</appender>

	<!-- 系统日志输出 -->
	<appender name="file_info" class="ch.qos.logback.core.rolling.RollingFileAppender">
	    <file>${log.path}/sys-info.log</file>
        <!-- 循环政策：基于时间创建日志文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件名格式 -->
			<fileNamePattern>${log.path}/sys-info.%d{yyyy-MM-dd}.log</fileNamePattern>
			<!-- 日志最大的历史 60天 -->
			<maxHistory>60</maxHistory>
		</rollingPolicy>
		<encoder>
			<pattern>${log.pattern}</pattern>
		</encoder>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 过滤的级别 -->
            <level>INFO</level>
            <!-- 匹配时的操作：接收（记录） -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配时的操作：拒绝（不记录） -->
            <onMismatch>DENY</onMismatch>
        </filter>
	</appender>
	
	<appender name="file_error" class="ch.qos.logback.core.rolling.RollingFileAppender">
	    <file>${log.path}/sys-error.log</file>
        <!-- 循环政策：基于时间创建日志文件 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 日志文件名格式 -->
            <fileNamePattern>${log.path}/sys-error.%d{yyyy-MM-dd}.log</fileNamePattern>
			<!-- 日志最大的历史 60天 -->
			<maxHistory>60</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${log.pattern}</pattern>
        </encoder>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 过滤的级别 -->
            <level>ERROR</level>
			<!-- 匹配时的操作：接收（记录） -->
            <onMatch>ACCEPT</onMatch>
			<!-- 不匹配时的操作：拒绝（不记录） -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
	
	<!-- 用户访问日志输出  -->
    <appender name="sys-user" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${log.path}/sys-user.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 按天回滚 daily -->
            <fileNamePattern>${log.path}/sys-user.%d{yyyy-MM-dd}.log</fileNamePattern>
            <!-- 日志最大的历史 60天 -->
            <maxHistory>60</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>${log.pattern}</pattern>
        </encoder>
    </appender>

<!--    <appender name="HDFS" class="">-->

<!--    </appender>-->

<!--    https://blog.csdn.net/warrah/article/details/78774547-->
<!--    https://blog.csdn.net/jy02268879/article/details/81024758-->
<!--    com.gilt.flume.logback.FlumeLogstashV1Appender    用这个没效果啦-->
<!--	<appender name="Mflume" class="com.teambytes.logback.flume.FlumeLogstashV1Appender">-->
<!--        <flumeAgents>-->
<!--            localhost:44444-->
<!--        </flumeAgents>-->
<!--        <flumeProperties>-->
<!--            connect-timeout=4000;-->
<!--            request-timeout=8000-->
<!--        </flumeProperties>-->
<!--        <reporterMaxThreadPoolSize>12</reporterMaxThreadPoolSize>-->
<!--        <reporterMaxQueueSize>200</reporterMaxQueueSize>-->
<!--&lt;!&ndash;        测试的时候改为1  原来为100&ndash;&gt;-->
<!--        <batchSize>1</batchSize>-->
<!--        <reportingWindow>1000</reportingWindow>-->
<!--        <additionalAvroHeaders>-->
<!--            myHeader = myValue-->
<!--        </additionalAvroHeaders>-->
<!--        <application>ruoyi</application>-->
<!--        <layout class="ch.qos.logback.classic.PatternLayout">-->
<!--            <pattern>%d{HH:mm:ss.SSS} %-5level %logger{36} - \(%file:%line\) - %message%n%ex</pattern>-->
<!--        </layout>-->

<!--    </appender>-->

<!--    <appender name="MKafka" class="com.github.danielwegener.logback.kafka.KafkaAppender">-->
<!--        <encoder>-->
<!--            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>-->
<!--        </encoder>-->
<!--        <topic>chas</topic>-->
<!--        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>-->
<!--        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>-->
<!--        <producerConfig>bootstrap.servers=localhost:9092</producerConfig>-->
<!--    </appender>-->

	<!-- 系统模块日志级别控制  -->
	<logger name="com.ruoyi" level="warn" />

	<!-- Spring日志级别控制  -->
	<logger name="org.springframework" level="warn"/>

    <!--    推荐模块日志级别  -->
    <logger name="com.ruoyi.recommend" level="warn">
        <appender-ref ref="console"/>
    </logger>

    <logger name="com.ruoyi.framework" level="info" additivity="false">
        <appender-ref ref="console"/>

<!--        <appender-ref ref="Mflume"/>-->

    </logger>

	<root level="warn">
		<appender-ref ref="console" />
	</root>
	
	<!--系统操作日志-->
    <root level="info">
        <appender-ref ref="file_info" />
        <appender-ref ref="file_error" />
<!--        <appender-ref ref="Mflume"/>-->
    </root>
	
	<!--系统用户操作日志-->
    <logger name="sys-user" level="warn">
        <appender-ref ref="sys-user"/>
    </logger>

</configuration> 